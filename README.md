# ðŸ—ï¸ Retail Lakehouse Project  
**Databricks â€¢ Apache Airflow â€¢ Delta Lake â€¢ Power BI**

---

## ðŸ“Œ Project Overview

This project implements a **production-grade Retail Data Lakehouse** using **Databricks**, **Apache Airflow**, **Delta Lake**, and **Power BI**, following a **Bronze â†’ Silver â†’ Gold** architecture with an automated **Data Quality (DQ) Gate**.

The solution demonstrates how raw transactional data can be ingested, validated, orchestrated, audited, and transformed into **trusted, analytics-ready datasets**, closely mirroring real-world enterprise data platforms.

---

## ðŸŽ¯ Key Objectives

- Build a scalable **Lakehouse architecture**
- Separate raw, clean, and business-ready data layers
- Enforce **data quality checks before analytics**
- Orchestrate pipelines using **Apache Airflow**
- Enable **safe reruns, observability, and failure handling**
- Deliver **Power BIâ€“ready Gold datasets**

---

## ðŸ§± Technology Stack

- **Databricks** â€“ Data processing & Delta Lake storage  
- **Apache Airflow (Dockerized)** â€“ External orchestration  
- **Delta Lake** â€“ ACID-compliant storage layers  
- **Power BI** â€“ Analytics and visualization  
- **Python / PySpark** â€“ Transformations and data quality logic  

---

## ðŸ›ï¸ High-Level Architecture

```text
Synthetic Retail Data
(Generated Transactions)
        â†“
Bronze Layer
Raw Delta Tables
(Immutable Ingestion)
        â†“
Silver Layer
Cleaned & Validated Data
(Deduplication, Parsing)
        â†“
Data Quality Gate
Validation Rules
(Fail / Pass Thresholds)
        â†“
Gold Layer
Business Aggregations
(BI-Optimized Tables)
        â†“
Power BI Dashboards
Reporting & Insights
```

---

## ðŸ“‚ Repository Structure (Overview)

```text
retail-lakehouse/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/               â†’ Airflow DAGs
â”‚   â”œâ”€â”€ Dockerfile          â†’ Airflow image
â”‚   â””â”€â”€ docker-compose.yml  â†’ Local orchestration
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ bronze/             â†’ Raw ingestion
â”‚   â”œâ”€â”€ silver/             â†’ Cleaning & DQ
â”‚   â””â”€â”€ gold/               â†’ Aggregations
â”œâ”€â”€ data_generator/         â†’ Synthetic data scripts
â”œâ”€â”€ data/                   â†’ Sample/reference data
â”œâ”€â”€ docs/                   â†’ Architecture & DQ docs
â”œâ”€â”€ powerbi/                â†’ Local dashboards
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ðŸš€ Key Features

Bronzeâ€“Silverâ€“Gold Lakehouse architecture

External orchestration using Apache Airflow

Explicit Data Quality Gate before Gold layer

Idempotent, rerunnable pipelines

Power BIâ€“ready analytics datasets

---

## ðŸ“Š Analytics Layer

The Gold layer outputs are designed to be directly consumed by **Power BI**, enabling:
- Revenue trends
- Store and product performance
- Customer-level insights
- Channel analysis
---

## ðŸ“Š Power BI Dashboards

The Gold-layer datasets produced by the lakehouse are consumed directly by **Power BI** to enable business reporting and analytics.

### Dashboard Highlights

#### Overview Dashboard
![Overview Dashboard](powerbi/screenshots/Executive_Overview.png) 

#### Revenue by Store
![Revenue by Store](powerbi/screenshots/Product_Performance.png)

#### Product Performance
![Product Performance](powerbi/screenshots/Store_Performance.png)

> Power BI `.pbix` files are intentionally excluded from version control.  
> Screenshots are provided for demonstration purposes.

---

## ðŸ§  Why This Project Matters

This project goes beyond simple ETL by demonstrating:
- Real-world **data governance practices**
- External orchestration instead of notebook chaining
- Production-style **quality enforcement**
- End-to-end ownership from ingestion to BI

---

## ðŸ“Œ Notes

- Secrets and environment variables are excluded via `.gitignore`
- Airflow logs and Power BI binaries are kept local only
- Detailed architecture and DQ logic can be found in `/docs`

---

## ðŸ‘¤ Author

**Kamran Habib**  
Data Analytics & Data Engineering Projects 
