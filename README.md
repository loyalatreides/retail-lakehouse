# ğŸ—ï¸ Retail Lakehouse Project  
**Databricks â€¢ Apache Airflow â€¢ Delta Lake â€¢ Power BI**

---

## ğŸ“Œ Project Overview

This project implements a **production-grade Retail Data Lakehouse** using **Databricks**, **Apache Airflow**, **Delta Lake**, and **Power BI**, following a **Bronze â†’ Silver â†’ Gold** architecture with an automated **Data Quality (DQ) Gate**.

The solution demonstrates how raw transactional data can be ingested, validated, orchestrated, audited, and transformed into **trusted, analytics-ready datasets**, closely mirroring real-world enterprise data platforms.

---

## ğŸ¯ Key Objectives

- Build a scalable **Lakehouse architecture**
- Separate raw, clean, and business-ready data layers
- Enforce **data quality checks before analytics**
- Orchestrate pipelines using **Apache Airflow**
- Enable **safe reruns, observability, and failure handling**
- Deliver **Power BIâ€“ready Gold datasets**

---

## ğŸ§± Technology Stack

- **Databricks** â€“ Data processing & Delta Lake storage  
- **Apache Airflow (Dockerized)** â€“ External orchestration  
- **Delta Lake** â€“ ACID-compliant storage layers  
- **Power BI** â€“ Analytics and visualization  
- **Python / PySpark** â€“ Transformations and data quality logic  

---

## ğŸ›ï¸ High-Level Architecture

```text
Synthetic Retail Data
(Generated Transactions)
        â†“
Bronze Layer
Raw Delta Tables
(Immutable Ingestion)
        â†“
Silver Layer
Cleaned & Validated Data
(Deduplication, Parsing)
        â†“
Data Quality Gate
Validation Rules
(Fail / Pass Thresholds)
        â†“
Gold Layer
Business Aggregations
(BI-Optimized Tables)
        â†“
Power BI Dashboards
Reporting & Insights
```

---

## ğŸ“‚ Repository Structure (Overview)

```text
retail-lakehouse/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/               â†’ Airflow DAGs
â”‚   â”œâ”€â”€ Dockerfile          â†’ Airflow image
â”‚   â””â”€â”€ docker-compose.yml  â†’ Local orchestration
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ bronze/             â†’ Raw ingestion
â”‚   â”œâ”€â”€ silver/             â†’ Cleaning & DQ
â”‚   â””â”€â”€ gold/               â†’ Aggregations
â”œâ”€â”€ data_generator/         â†’ Synthetic data scripts
â”œâ”€â”€ data/                   â†’ Sample/reference data
â”œâ”€â”€ docs/                   â†’ Architecture & DQ docs
â”œâ”€â”€ powerbi/                â†’ Local dashboards
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸš€ Key Features

Bronzeâ€“Silverâ€“Gold Lakehouse architecture

External orchestration using Apache Airflow

Explicit Data Quality Gate before Gold layer

Idempotent, rerunnable pipelines

Power BIâ€“ready analytics datasets

---

## ğŸ“Š Analytics Layer

The Gold layer outputs are designed to be directly consumed by **Power BI**, enabling:
- Revenue trends
- Store and product performance
- Customer-level insights
- Channel analysis

*(Power BI `.pbix` files are intentionally excluded from version control.)*

---

## ğŸ§  Why This Project Matters

This project goes beyond simple ETL by demonstrating:
- Real-world **data governance practices**
- External orchestration instead of notebook chaining
- Production-style **quality enforcement**
- End-to-end ownership from ingestion to BI

---

## ğŸ“Œ Notes

- Secrets and environment variables are excluded via `.gitignore`
- Airflow logs and Power BI binaries are kept local only
- Detailed architecture and DQ logic can be found in `/docs`

---

## ğŸ‘¤ Author

**Kamran Habib**  
Data Analytics & Data Engineering Projects 
